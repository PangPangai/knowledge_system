# PDF 文本提取质量 (乱码) 检测指南

在处理 PDF 文档并将其转换为 Markdown 用于 RAG 系统时，可能会遇到文本提取出全是乱码（如 `Chu<..`）的情况。本项目集成了自动检测机制，本指南详细说明其原理与处理方法。

## 1. 乱码根源：Identity-H 编码与 ToUnicode 缺失

PDF 文档中的字符显示依赖于 **字形 (Glyphs)** 到 **Unicode 字符** 的映射表。

- **正常 PDF**：包含 `ToUnicode` 映射表，`PyMuPDF` 等工具可以轻松将字形 ID 还原为可读文字。
- **问题 PDF (常见于 Synopsys 文档)**：
  - 使用了 **Identity-H** 编码。
  - 为了减小体积，只嵌入了字体的子集。
  - **核心问题**：生成 PDF 时丢失或恶意移除了 `ToUnicode` 映射表。
  - **结果**：提取出的字符是字体的内部索引码，由于没有“字典”，这些索引码被解释为无意义的符号（如 `<`、`>` 等）。

## 2. 检测原理

系统通过以下启发式算法自动识别潜在的乱码文件：

1.  **高频垃圾特征 (Garbage Pattern Recognition)**：
    - 搜索已知的乱码模式，例如字符串中包含大量的 `Chu<` 或 `untdilbtm` 等 Synopsys 文档常见的映射错误模式。
2.  **ASCII 密度检查 (ASCII Density Calculation)**：
    - 计算提取文本中标准字符（a-z, A-Z, 0-9, 常见标点、换行）所占的比例。
    - **判定标准**：如果标准字符占比低于 80%，且文档主要语言为英语，则判定为乱码。
3.  **多点采样**：
    - 同时扫描文档的前部、中部和后部页面，防止由于单页特殊格式（如全图页）导致的误报。

## 3. 处理流程

当系统检测到 PDF 存在乱码时，将采取以下行动：

- **自动拦截**：在 `rebuild_index.py` 处理过程中，会自动跳过标记为 `GARBLED` 的文件。
- **日志提示**：输出明确的错误信息，告知用户该文件由于编码问题无法提取，需要 OCR。
- **OCR 补救 (可选)**：针对此类文件，无法通过代码提取。必须先使用外部 OCR 工具（如 Adobe Acrobat OCR 功能、Tesseract 或 RapidOCR）对 PDF 进行预处理，将其转换为可搜索的 PDF 后再提交给本系统。

## 4. 如何测试

如果您需要手动验证一个 PDF 是否有此问题，可以运行：
```powershell
py -3.11 backend/debug_test/check_pdfs_encoding.py
```
该脚本会生成一份健康报告。
