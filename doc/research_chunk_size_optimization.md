# RAG Chunk Size 深度调研报告

## 核心结论

**没有"最优"的固定值**，但行业基准显示：

| 场景类型     | 推荐 Token 数 | 说明                                   |
| ------------ | ------------- | -------------------------------------- |
| 精确事实检索 | 128-256       | 关键词匹配敏感，如"XX命令的参数是什么" |
| 通用问答     | 256-512       | **最常见的起点**                       |
| 复杂上下文   | 512-1024      | 研究论文、技术文档、需要完整段落理解   |
| 金融分析     | 1024          | FinanceBench 数据集实测最优            |
| ≥2048        | ⚠️ 不推荐      | 多项研究显示准确率下降                 |

---

## 场景-Size 匹配指南

### 1. 技术手册 / EDA 文档（如 FCUG、PTUG）
**推荐：512-1024 tokens + 结构感知切分**

- **原因**：
  - 章节层次清晰（Chapter → Section → Subsection），应按标题切分而非硬切
  - 包含大量表格，必须保持完整
  - 跨段落的概念解释常见

- **最佳实践**：
  - 使用 `MarkdownHeaderTextSplitter` 按 `#`, `##`, `###` 切分
  - 表格作为独立 Chunk，不拆分
  - Overlap 设为 10-20%（64-128 tokens）

### 2. 代码/脚本文档
**推荐：按语法单元切分**

- 函数/类作为独立 Chunk
- 保留 Docstring
- 包含 5-10 行上下文（依赖引入等）

### 3. 问答型知识库（FAQ）
**推荐：128-256 tokens**

- 每个 QA 对作为独立 Chunk
- 精确匹配优先

### 4. 长篇叙述（报告、论文）
**推荐：512-1024 tokens**

- 保留段落完整性
- 较大 Overlap（20%）

---

## Overlap（重叠）设置

| Chunk Size | 推荐 Overlap | 比例   |
| ---------- | ------------ | ------ |
| 256        | 32-64        | 12-25% |
| 512        | 64-128       | 12-25% |
| 1024       | 128-200      | 12-20% |

**作用**：防止关键信息被切断，提高召回率。

---

## 高级策略

### Parent-Child (Small-to-Big)
- **索引**：用小 Chunk（128-256）做 Embedding，检索精准
- **生成**：命中后回溯到父 Chunk（整个段落/章节），给 LLM 更多上下文
- **适用**：兼顾精确检索和完整回答

### 分层切分 (Hierarchical)
- Level 1: 章节级（整章）
- Level 2: 段落级（单个 Section）
- Level 3: 句子级

可根据问题类型选择查询哪一层。

---

## 当前系统配置 vs 建议

| 参数            | 当前值       | 建议值           | 说明                                |
| --------------- | ------------ | ---------------- | ----------------------------------- |
| `CHUNK_SIZE`    | 1000 (字符)  | 512-768 (tokens) | 当前按字符，中文约 1.5 字符/token   |
| `CHUNK_OVERLAP` | 200          | 10-20% of size   | 保持比例稳定                        |
| 切分方式        | Header-Aware | ✅ 正确           | 已使用 `MarkdownHeaderTextSplitter` |

### 换算参考
- 英文：≈ 4 字符/token
- 中文：≈ 1.5-2 字符/token
- 当前 1000 字符 ≈ 500-650 tokens（中英混合）

---

## 建议行动

1. **保持当前 1000 字符**（≈512 tokens）作为默认值
2. **确保表格不被拆分**（检查 [_chunk_markdown](file:///c:/Niexingyu/AI/TRAE/backend/%E7%AC%94%E8%AE%B0/knowledge_system/backend/rag_engine.py#516-556) 逻辑）
3. **如果遇到"回答不完整"问题**：尝试增大到 1500-2000 字符
4. **如果遇到"匹配不精确"问题**：减小到 500-800 字符

---

## 参考来源

- NVIDIA RAG Benchmark (2024)
- LlamaIndex Chunk Size Study
- Milvus Chunking Best Practices
- Airbyte RAG Chunking Guide
